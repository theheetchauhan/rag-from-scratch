{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The Complete Guide to Query Routing in RAG Applications\n",
        "\n",
        "## What We're Building Today\n",
        "\n",
        "Imagine you're building an AI assistant for a large company. This company has thousands of documents spread across different departments - technical documentation for developers, product guides for customers, HR policies for employees, and support articles in multiple languages. When someone asks a question, how does your AI know where to look?\n",
        "\n",
        "That's where query routing comes in. Think of it as building a smart traffic control system for questions. Just like a GPS routes you through the fastest path to your destination, query routing sends each question to the most appropriate knowledge base, making your AI faster, cheaper, and more accurate.\n",
        "\n",
        "By the end of this tutorial, you'll understand not just how to build these routing systems, but why each approach works the way it does. We'll start simple and gradually build up to production-ready implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up Our Environment\n",
        "\n",
        "Before we dive in, let's get our tools ready. We'll be using three main libraries that work beautifully together. LangChain helps us orchestrate AI workflows, OpenAI provides the intelligence, and ChromaDB acts as our smart storage system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, install everything we need\n",
        "# Run this cell once to install all required packages\n",
        "!pip install langchain langchain-openai chromadb openai tiktoken numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all our tools\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from enum import Enum\n",
        "import time\n",
        "\n",
        "# LangChain components - our AI orchestration toolkit\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "# ChromaDB - our vector database for storing and searching embeddings\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# OpenAI direct imports for specific features\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key here\n",
        "# Get yours at: https://platform.openai.com/api-keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<your-api-key-here>\"  # Replace with your actual API key\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "print(\"âœ… Environment ready! Let's build some routers.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building Our Knowledge Bases\n",
        "\n",
        "Before we can route queries, we need somewhere to route them to. Let's create a realistic scenario with multiple knowledge bases. We'll simulate a company with different types of documentation, each serving a different purpose. This will help us see why routing matters - sending a technical API question to the HR knowledge base would give terrible results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's create comprehensive sample documents for each knowledge base\n",
        "# In production, these would come from your actual documentation\n",
        "\n",
        "# Technical documentation - for developers and technical users\n",
        "technical_docs = [\n",
        "    \"\"\"API Authentication Guide: Every API request must include an Authorization header \n",
        "    with your API key in the format 'Bearer YOUR_API_KEY'. Keys can be generated from \n",
        "    your dashboard. For enhanced security, you can also use OAuth 2.0 flow for user-specific \n",
        "    actions. Rate limits are 100 requests per minute for standard tier, 1000 for premium.\"\"\",\n",
        "    \n",
        "    \"\"\"Webhook Configuration: Register webhooks via POST to /api/webhooks with a JSON payload \n",
        "    containing 'url' and 'events' array. We'll send POST requests to your endpoint with \n",
        "    event data. Always verify webhook signatures using HMAC-SHA256 with your webhook secret \n",
        "    to ensure requests are from us.\"\"\",\n",
        "    \n",
        "    \"\"\"Error Handling Best Practices: Implement exponential backoff for rate limit errors (429). \n",
        "    Start with 1 second delay, double after each retry, max 5 retries. For 5xx errors, \n",
        "    retry up to 3 times. Log all errors with correlation IDs for debugging. Common errors: \n",
        "    400 (bad request), 401 (unauthorized), 403 (forbidden), 404 (not found).\"\"\",\n",
        "    \n",
        "    \"\"\"Database Connection Pooling: Use connection pools to improve performance. Recommended \n",
        "    settings: min_size=5, max_size=20, timeout=30s. For PostgreSQL, use SSL mode 'require' \n",
        "    in production. Connection string format: postgresql://user:pass@host:5432/dbname?sslmode=require.\"\"\",\n",
        "    \n",
        "    \"\"\"SDK Installation: Python: pip install our-sdk. JavaScript: npm install @company/sdk. \n",
        "    Java: Add Maven dependency. All SDKs support async operations and automatic retries. \n",
        "    Initialize with your API key: client = OurSDK(api_key='YOUR_KEY').\"\"\"\n",
        "]\n",
        "\n",
        "# Product documentation - for customers and sales\n",
        "product_docs = [\n",
        "    \"\"\"Pricing Plans Overview: Starter Plan ($29/month) - up to 1,000 API calls, 5 team members, \n",
        "    basic support. Professional ($99/month) - 10,000 API calls, unlimited team members, \n",
        "    priority support, advanced analytics. Enterprise (custom pricing) - unlimited API calls, \n",
        "    dedicated support, SLA guarantee, custom integrations.\"\"\",\n",
        "    \n",
        "    \"\"\"Key Features: Real-time collaboration with presence indicators, version control for \n",
        "    all changes, advanced AI-powered search, customizable dashboards, 50+ integrations \n",
        "    including Slack, Jira, GitHub. Mobile apps for iOS and Android with offline mode. \n",
        "    End-to-end encryption for all data.\"\"\",\n",
        "    \n",
        "    \"\"\"Getting Started Guide: Sign up for a free 14-day trial (no credit card required). \n",
        "    Verify your email and complete onboarding. Import existing data via CSV or API. \n",
        "    Invite team members. Configure your first workflow. Most users are productive within \n",
        "    30 minutes. We offer free onboarding calls for Professional and Enterprise plans.\"\"\",\n",
        "    \n",
        "    \"\"\"System Requirements: Browser: Chrome 90+, Firefox 88+, Safari 14+, Edge 90+. \n",
        "    Desktop app: Windows 10+, macOS 11+, Ubuntu 20.04+. Minimum 4GB RAM, 2GB disk space. \n",
        "    Internet connection required (minimum 1 Mbps). Mobile: iOS 14+ or Android 8+.\"\"\",\n",
        "    \n",
        "    \"\"\"Trial and Billing: 14-day free trial includes all Professional features. After trial, \n",
        "    choose a plan or continue with limited free tier (100 API calls/month). Annual billing \n",
        "    saves 20%. Cancel anytime, data retained for 30 days. Refunds available within 30 days \n",
        "    of purchase.\"\"\"\n",
        "]\n",
        "\n",
        "# HR/Policy documentation - for employees\n",
        "policy_docs = [\n",
        "    \"\"\"Vacation Policy: Full-time employees receive 15 days PTO first year, 20 days after \n",
        "    two years, 25 days after five years. Unused PTO carries over (max 5 days). Request \n",
        "    time off at least 2 weeks in advance via HR portal. Sick leave is separate - 10 days \n",
        "    per year. Parental leave: 12 weeks paid.\"\"\",\n",
        "    \n",
        "    \"\"\"Remote Work Guidelines: Employees may work remotely up to 3 days per week after \n",
        "    90-day probation. Core hours are 10 AM - 3 PM in your local timezone. Provide your \n",
        "    own internet (reimbursement available). Annual home office stipend of $500. Must be \n",
        "    available for critical meetings. International remote work requires VP approval.\"\"\",\n",
        "    \n",
        "    \"\"\"Expense Reimbursement: Submit expenses within 30 days via Expensify. Receipts required \n",
        "    for amounts over $25. Pre-approval needed for expenses over $500. Travel meals: \n",
        "    Breakfast $20, Lunch $30, Dinner $50. Economy flights for trips under 5 hours, \n",
        "    business class for longer. Hotels up to $200/night.\"\"\",\n",
        "    \n",
        "    \"\"\"Professional Development: Annual budget of $2,000 per employee for courses, conferences, \n",
        "    and books. Additional funding available with manager approval. Company pays for job-relevant \n",
        "    certifications. Study leave available: 5 days per year. Tuition reimbursement for \n",
        "    degree programs: up to $5,000/year.\"\"\",\n",
        "    \n",
        "    \"\"\"Code of Conduct: Treat everyone with respect and professionalism. No discrimination \n",
        "    or harassment tolerated. Maintain confidentiality of company and customer information. \n",
        "    Disclose conflicts of interest. Report violations to HR or use anonymous hotline. \n",
        "    Social media policy: Don't share confidential info, be respectful, clarify personal \n",
        "    opinions vs company positions.\"\"\"\n",
        "]\n",
        "\n",
        "# Support documentation in different languages (for language routing demo)\n",
        "support_docs_english = [\n",
        "    \"\"\"Password Reset: Click 'Forgot Password' on the login page. Enter your email address. \n",
        "    Check your email for reset link (check spam folder). Link expires in 1 hour. Choose \n",
        "    a strong password with 8+ characters, including uppercase, lowercase, and numbers.\"\"\",\n",
        "    \n",
        "    \"\"\"Account Security: Enable two-factor authentication in Settings > Security. We support \n",
        "    SMS, authenticator apps, and hardware keys. Never share your password. We'll never ask \n",
        "    for your password via email or phone. Review login history regularly.\"\"\"\n",
        "]\n",
        "\n",
        "support_docs_spanish = [\n",
        "    \"\"\"Restablecimiento de ContraseÃ±a: Haga clic en 'OlvidÃ© mi contraseÃ±a' en la pÃ¡gina de inicio. \n",
        "    Ingrese su correo electrÃ³nico. Revise su correo para el enlace (verifique spam). \n",
        "    El enlace expira en 1 hora. Elija una contraseÃ±a segura con 8+ caracteres.\"\"\",\n",
        "    \n",
        "    \"\"\"Seguridad de Cuenta: Active autenticaciÃ³n de dos factores en ConfiguraciÃ³n > Seguridad. \n",
        "    Soportamos SMS, aplicaciones de autenticaciÃ³n y llaves de hardware. Nunca comparta su \n",
        "    contraseÃ±a. Nunca le pediremos su contraseÃ±a por correo o telÃ©fono.\"\"\"\n",
        "]\n",
        "\n",
        "print(\"ðŸ“š Knowledge bases created successfully!\")\n",
        "print(f\"\\nWe now have:\")\n",
        "print(f\"  - {len(technical_docs)} technical documents\")\n",
        "print(f\"  - {len(product_docs)} product documents\")\n",
        "print(f\"  - {len(policy_docs)} policy documents\")\n",
        "print(f\"  - {len(support_docs_english) + len(support_docs_spanish)} support documents (multilingual)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Up ChromaDB Collections\n",
        "\n",
        "Now we need to store these documents in a way that makes them searchable. ChromaDB is perfect for this because it automatically converts text into embeddings (numerical representations that capture meaning) and lets us search by similarity. Think of it as creating smart indexes that understand concepts, not just keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize ChromaDB with a clean slate\n",
        "# In production, you'd use persist_directory to save the database\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Create an embedding function that will convert text to vectors\n",
        "# We're using OpenAI's embedding model which understands context and meaning\n",
        "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    model_name=\"text-embedding-3-small\"  # Fast and efficient model\n",
        ")\n",
        "\n",
        "# Helper function to create or reset a collection\n",
        "def create_collection(name: str, documents: List[str]) -> chromadb.Collection:\n",
        "    \"\"\"Create a ChromaDB collection and populate it with documents\"\"\"\n",
        "    \n",
        "    # Delete existing collection if it exists (for clean reruns)\n",
        "    try:\n",
        "        chroma_client.delete_collection(name=name)\n",
        "    except:\n",
        "        pass  # Collection doesn't exist, that's fine\n",
        "    \n",
        "    # Create new collection - casting the embedding function to resolve type issues\n",
        "    collection = chroma_client.create_collection(\n",
        "        name=name,\n",
        "        embedding_function=openai_ef  # type: ignore\n",
        "    )\n",
        "    \n",
        "    # Add documents with metadata\n",
        "    for i, doc in enumerate(documents):\n",
        "        collection.add(\n",
        "            documents=[doc],\n",
        "            ids=[f\"{name}_{i}\"],\n",
        "            metadatas=[{\"source\": name, \"index\": i}]\n",
        "        )\n",
        "    \n",
        "    return collection\n",
        "\n",
        "# Alternative approach: Create collection without embedding function first\n",
        "def create_collection_alt(name: str, documents: List[str]) -> chromadb.Collection:\n",
        "    \"\"\"Alternative: Create collection without embedding function in constructor\"\"\"\n",
        "    \n",
        "    # Delete existing collection if it exists (for clean reruns)\n",
        "    try:\n",
        "        chroma_client.delete_collection(name=name)\n",
        "    except:\n",
        "        pass  # Collection doesn't exist, that's fine\n",
        "    \n",
        "    # Create new collection without embedding function\n",
        "    collection = chroma_client.create_collection(name=name)\n",
        "    \n",
        "    # Add documents with the embedding function specified in add()\n",
        "    for i, doc in enumerate(documents):\n",
        "        collection.add(\n",
        "            documents=[doc],\n",
        "            ids=[f\"{name}_{i}\"],\n",
        "            metadatas=[{\"source\": name, \"index\": i}],\n",
        "            embeddings=openai_ef([doc])  # Generate embeddings explicitly\n",
        "        )\n",
        "    \n",
        "    return collection\n",
        "\n",
        "# Create all our collections using the primary approach\n",
        "print(\"ðŸ”„ Creating ChromaDB collections...\")\n",
        "\n",
        "technical_collection = create_collection(\"technical\", technical_docs)\n",
        "print(\"âœ… Technical collection created\")\n",
        "\n",
        "product_collection = create_collection(\"product\", product_docs)\n",
        "print(\"âœ… Product collection created\")\n",
        "\n",
        "policy_collection = create_collection(\"policy\", policy_docs)\n",
        "print(\"âœ… Policy collection created\")\n",
        "\n",
        "support_en_collection = create_collection(\"support_en\", support_docs_english)\n",
        "print(\"âœ… English support collection created\")\n",
        "\n",
        "support_es_collection = create_collection(\"support_es\", support_docs_spanish)\n",
        "print(\"âœ… Spanish support collection created\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ All collections ready for routing!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Rule-Based Router\n",
        "\n",
        "Let's start with the simplest approach - rule-based routing. This is like having a checklist: if you see certain keywords, you know exactly where to route the query. While simple, this approach is incredibly fast and predictable, making it perfect for scenarios where you have clear, domain-specific terminology."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RuleBasedRouter:\n",
        "    \"\"\"\n",
        "    A simple but effective router that uses keyword patterns.\n",
        "    Think of this as a smart filter that looks for specific terms.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Define routing rules as patterns with weights\n",
        "        # Higher weight = stronger signal that this is the right route\n",
        "        self.rules = {\n",
        "            \"technical\": [\n",
        "                (r\"\\bAPI\\b\", 5),          # \\b means word boundary - matches \"API\" but not \"RAPID\"\n",
        "                (r\"\\bwebhook\", 4),\n",
        "                (r\"\\berror\\b\", 3),\n",
        "                (r\"\\bcode\\b\", 3),\n",
        "                (r\"\\bSDK\\b\", 4),\n",
        "                (r\"\\bauthenticat\", 4),    # Matches authentication, authenticate, etc.\n",
        "                (r\"\\bintegrat\", 3),\n",
        "                (r\"\\bdatabase\\b\", 3),\n",
        "                (r\"\\b(GET|POST|PUT|DELETE)\\b\", 4),  # HTTP methods\n",
        "                (r\"\\bendpoint\", 3),\n",
        "                (r\"\\bOAuth\\b\", 4),\n",
        "                (r\"\\brate limit\", 3)\n",
        "            ],\n",
        "            \"product\": [\n",
        "                (r\"\\bpric\", 5),           # Matches price, pricing\n",
        "                (r\"\\bplan\\b\", 4),\n",
        "                (r\"\\btrial\\b\", 4),\n",
        "                (r\"\\bfeature\", 3),\n",
        "                (r\"\\b(starter|professional|enterprise)\\b\", 4),\n",
        "                (r\"\\bbilling\\b\", 4),\n",
        "                (r\"\\bsubscription\", 3),\n",
        "                (r\"\\brequirement\", 3),\n",
        "                (r\"\\brefund\", 3),\n",
        "                (r\"\\bcancel\", 3)\n",
        "            ],\n",
        "            \"policy\": [\n",
        "                (r\"\\bvacation\\b\", 5),\n",
        "                (r\"\\bPTO\\b\", 5),\n",
        "                (r\"\\bremote work\", 4),\n",
        "                (r\"\\bexpense\", 4),\n",
        "                (r\"\\breimburs\", 4),\n",
        "                (r\"\\bpolicy\\b\", 3),\n",
        "                (r\"\\bHR\\b\", 4),\n",
        "                (r\"\\bemployee\", 3),\n",
        "                (r\"\\bsick leave\", 4),\n",
        "                (r\"\\bconduct\\b\", 3)\n",
        "            ]\n",
        "        }\n",
        "    \n",
        "    def route(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze the query and determine the best route based on keyword patterns.\n",
        "        Returns route decision with confidence scores.\n",
        "        \"\"\"\n",
        "        query_lower = query.lower()\n",
        "        scores = {}\n",
        "        matched_patterns = {}\n",
        "        \n",
        "        # Check each route's patterns\n",
        "        for route, patterns in self.rules.items():\n",
        "            total_score = 0\n",
        "            matches = []\n",
        "            \n",
        "            for pattern, weight in patterns:\n",
        "                if re.search(pattern, query_lower):\n",
        "                    total_score += weight\n",
        "                    matches.append(pattern)\n",
        "            \n",
        "            scores[route] = total_score\n",
        "            matched_patterns[route] = matches\n",
        "        \n",
        "        # Determine the best route - fix the type issue\n",
        "        best_route = max(scores.keys(), key=lambda k: scores[k])\n",
        "        \n",
        "        # If no patterns matched, default to product (most general)\n",
        "        if scores[best_route] == 0:\n",
        "            best_route = \"product\"\n",
        "            confidence = \"low\"\n",
        "        else:\n",
        "            # Calculate confidence based on score difference\n",
        "            sorted_scores = sorted(scores.values(), reverse=True)\n",
        "            if len(sorted_scores) > 1 and sorted_scores[0] > sorted_scores[1] * 2:\n",
        "                confidence = \"high\"\n",
        "            elif len(sorted_scores) > 1 and sorted_scores[0] > sorted_scores[1] * 1.5:\n",
        "                confidence = \"medium\"\n",
        "            else:\n",
        "                confidence = \"low\"\n",
        "        \n",
        "        return {\n",
        "            \"route\": best_route,\n",
        "            \"confidence\": confidence,\n",
        "            \"score\": scores[best_route],\n",
        "            \"all_scores\": scores,\n",
        "            \"matched_patterns\": matched_patterns[best_route]\n",
        "        }\n",
        "\n",
        "# Let's test our rule-based router\n",
        "rule_router = RuleBasedRouter()\n",
        "\n",
        "test_queries = [\n",
        "    \"How do I authenticate my API requests?\",\n",
        "    \"What's the price of the enterprise plan?\",\n",
        "    \"Can I work from home on Fridays?\",\n",
        "    \"My webhook isn't receiving events\",\n",
        "    \"How much vacation time do I get?\"\n",
        "]\n",
        "\n",
        "print(\"ðŸ§ª Testing Rule-Based Router\\n\" + \"=\"*50)\n",
        "for query in test_queries:\n",
        "    result = rule_router.route(query)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"â†’ Route: {result['route']} (confidence: {result['confidence']})\")\n",
        "    print(f\"  Matched patterns: {result['matched_patterns']}\")\n",
        "    print(f\"  Scores: {result['all_scores']}\")\n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Semantic Router\n",
        "\n",
        "Now let's build something more sophisticated. Semantic routing understands the meaning behind words, not just the words themselves. It works by comparing the query's embedding (its meaning in mathematical form) with pre-computed embeddings of example questions for each route. This allows it to understand that \"system crash\" and \"application freezing\" are related concepts even though they share no keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SemanticRouter:\n",
        "    \"\"\"\n",
        "    Routes queries based on semantic similarity to example questions.\n",
        "    This is like having a router that actually understands meaning.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Initialize the embedding model\n",
        "        self.embeddings = OpenAIEmbeddings(\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        \n",
        "        # Define example queries for each route\n",
        "        # These serve as \"semantic anchors\" - representative questions for each category\n",
        "        self.route_examples = {\n",
        "            \"technical\": [\n",
        "                \"How do I integrate your API?\",\n",
        "                \"Getting 401 unauthorized error\",\n",
        "                \"Webhook signature validation failing\",\n",
        "                \"Database connection timeout issues\",\n",
        "                \"Need help with SDK installation\",\n",
        "                \"Rate limiting best practices\",\n",
        "                \"OAuth flow not working correctly\",\n",
        "                \"How to handle pagination in API responses\"\n",
        "            ],\n",
        "            \"product\": [\n",
        "                \"What features are included?\",\n",
        "                \"Difference between plans\",\n",
        "                \"How much does it cost?\",\n",
        "                \"Can I try before buying?\",\n",
        "                \"What are the system requirements?\",\n",
        "                \"Do you offer discounts?\",\n",
        "                \"How to upgrade my plan\",\n",
        "                \"Is there a free tier available?\"\n",
        "            ],\n",
        "            \"policy\": [\n",
        "                \"How many vacation days do I have?\",\n",
        "                \"Remote work policy details\",\n",
        "                \"How to submit expense reports\",\n",
        "                \"Professional development budget\",\n",
        "                \"Sick leave policy\",\n",
        "                \"Company code of conduct\",\n",
        "                \"Parental leave benefits\",\n",
        "                \"How to request time off\"\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        # Pre-compute embeddings for all examples\n",
        "        # This is done once at initialization for efficiency\n",
        "        print(\"ðŸ§® Computing semantic embeddings for route examples...\")\n",
        "        self.route_embeddings = {}\n",
        "        \n",
        "        for route, examples in self.route_examples.items():\n",
        "            # Get embeddings for all examples in one API call (more efficient)\n",
        "            embeddings = self.embeddings.embed_documents(examples)\n",
        "            self.route_embeddings[route] = embeddings\n",
        "            print(f\"  âœ“ Computed {len(embeddings)} embeddings for {route}\")\n",
        "    \n",
        "    def cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate cosine similarity between two vectors.\n",
        "        Returns a value between -1 and 1, where 1 means identical direction.\n",
        "        \"\"\"\n",
        "        # vec1 and vec2 are already numpy arrays\n",
        "        dot_product = np.dot(vec1, vec2)\n",
        "        norm1 = np.linalg.norm(vec1)\n",
        "        norm2 = np.linalg.norm(vec2)\n",
        "        \n",
        "        # Avoid division by zero\n",
        "        if norm1 == 0 or norm2 == 0:\n",
        "            return 0\n",
        "        \n",
        "        return dot_product / (norm1 * norm2)\n",
        "    \n",
        "    def route(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Route query based on semantic similarity to example questions.\n",
        "        \"\"\"\n",
        "        # Get embedding for the query\n",
        "        query_embedding = np.array(self.embeddings.embed_query(query))\n",
        "        \n",
        "        # Calculate similarity with each route's examples\n",
        "        route_scores = {}\n",
        "        best_matches = {}\n",
        "        \n",
        "        for route, example_embeddings in self.route_embeddings.items():\n",
        "            similarities = []\n",
        "            \n",
        "            # Compare with each example\n",
        "            for i, example_embedding in enumerate(example_embeddings):\n",
        "                similarity = self.cosine_similarity(\n",
        "                    query_embedding, np.array(example_embedding)\n",
        "                )\n",
        "                similarities.append(similarity)\n",
        "            \n",
        "            # Use the maximum similarity as the route score\n",
        "            # You could also use mean or top-k average\n",
        "            max_similarity = max(similarities)\n",
        "            max_index = similarities.index(max_similarity)\n",
        "            \n",
        "            route_scores[route] = max_similarity\n",
        "            best_matches[route] = {\n",
        "                \"example\": self.route_examples[route][max_index],\n",
        "                \"similarity\": max_similarity\n",
        "            }\n",
        "        \n",
        "        # Select the route with highest similarity\n",
        "        best_route = max(route_scores.keys(), key=lambda k: route_scores[k])\n",
        "        \n",
        "        # Determine confidence based on similarity score\n",
        "        similarity = route_scores[best_route]\n",
        "        if similarity > 0.85:\n",
        "            confidence = \"high\"\n",
        "        elif similarity > 0.70:\n",
        "            confidence = \"medium\"\n",
        "        else:\n",
        "            confidence = \"low\"\n",
        "        \n",
        "        return {\n",
        "            \"route\": best_route,\n",
        "            \"confidence\": confidence,\n",
        "            \"similarity\": similarity,\n",
        "            \"all_scores\": route_scores,\n",
        "            \"best_match\": best_matches[best_route]\n",
        "        }\n",
        "\n",
        "# Initialize and test the semantic router\n",
        "semantic_router = SemanticRouter()\n",
        "\n",
        "test_queries = [\n",
        "    \"My application keeps crashing when calling your service\",  # Similar to technical errors\n",
        "    \"What's included in your most expensive option?\",          # Similar to pricing/plans\n",
        "    \"I need to take some days off next month\",                # Similar to vacation policy\n",
        "    \"The system is too slow\",                                  # Ambiguous - could be technical or product\n",
        "]\n",
        "\n",
        "print(\"\\nðŸ§ª Testing Semantic Router\\n\" + \"=\"*50)\n",
        "for query in test_queries:\n",
        "    result = semantic_router.route(query)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"â†’ Route: {result['route']} (confidence: {result['confidence']})\")\n",
        "    print(f\"  Best match: '{result['best_match']['example']}'\")\n",
        "    print(f\"  Similarity: {result['best_match']['similarity']:.3f}\")\n",
        "    print(f\"  All scores: {', '.join(f'{k}:{v:.3f}' for k,v in result['all_scores'].items())}\")\n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3: LLM Completion Router\n",
        "\n",
        "Sometimes you need the full reasoning power of a language model to make routing decisions. This approach uses GPT to analyze the query and decide where it should go. While more expensive and slower than previous methods, it can handle complex, ambiguous queries that would confuse simpler routers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LLMCompletionRouter:\n",
        "    \"\"\"\n",
        "    Uses a language model to intelligently route queries.\n",
        "    This is like having an expert analyst decide where each question should go.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model: str = \"gpt-3.5-turbo\"):\n",
        "        # Initialize the language model\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=model,\n",
        "            temperature=0  # Set to 0 for consistent, deterministic routing\n",
        "        )\n",
        "        \n",
        "        # Create a detailed prompt template that guides the model's decision\n",
        "        self.routing_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a query router for a company's knowledge base system. Your job is to analyze \n",
        "incoming queries and determine which knowledge base would best answer them.\n",
        "\n",
        "Available knowledge bases:\n",
        "1. \"technical\" - API documentation, SDKs, webhooks, integration guides, error codes, \n",
        "   debugging help, database configurations, authentication methods\n",
        "   \n",
        "2. \"product\" - Pricing plans, features, system requirements, trial information, \n",
        "   billing, subscriptions, getting started guides, product capabilities\n",
        "   \n",
        "3. \"policy\" - HR policies, vacation/PTO, remote work, expense reimbursement, \n",
        "   code of conduct, employee benefits, professional development\n",
        "\n",
        "Analyze this query and respond with ONLY the knowledge base name (technical, product, or policy).\n",
        "Also provide a confidence level (high, medium, low) and brief reasoning.\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Respond in this exact format:\n",
        "ROUTE: [knowledge_base]\n",
        "CONFIDENCE: [high/medium/low]\n",
        "REASON: [one sentence explanation]\n",
        "\"\"\")\n",
        "        \n",
        "        # Alternative prompt for handling ambiguous queries\n",
        "        self.clarification_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "This query might be ambiguous or could relate to multiple knowledge bases.\n",
        "Query: {query}\n",
        "\n",
        "Could this query potentially relate to multiple knowledge bases? If yes, list all relevant ones.\n",
        "If the query needs clarification, suggest what information would help route it better.\n",
        "\n",
        "Respond in this format:\n",
        "PRIMARY_ROUTE: [most likely knowledge base]\n",
        "ALTERNATIVE_ROUTES: [other possible knowledge bases, comma-separated, or \"none\"]\n",
        "CLARIFICATION_NEEDED: [yes/no]\n",
        "CLARIFICATION: [what to ask the user, or \"none\"]\n",
        "\"\"\")\n",
        "    \n",
        "    def route(self, query: str, handle_ambiguity: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Route a query using LLM analysis.\n",
        "        \n",
        "        Args:\n",
        "            query: The user's question\n",
        "            handle_ambiguity: If True, use additional analysis for ambiguous queries\n",
        "        \"\"\"\n",
        "        # Create the routing chain\n",
        "        routing_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=self.routing_prompt\n",
        "        )\n",
        "        \n",
        "        # Get routing decision\n",
        "        with get_openai_callback() as cb:\n",
        "            response = routing_chain.run(query=query)\n",
        "            tokens_used = cb.total_tokens\n",
        "            cost = cb.total_cost\n",
        "        \n",
        "        # Parse the response\n",
        "        lines = response.strip().split('\\n')\n",
        "        route = \"product\"  # default\n",
        "        confidence = \"low\"\n",
        "        reason = \"Unable to determine\"\n",
        "        \n",
        "        for line in lines:\n",
        "            if line.startswith(\"ROUTE:\"):\n",
        "                route = line.replace(\"ROUTE:\", \"\").strip().lower()\n",
        "            elif line.startswith(\"CONFIDENCE:\"):\n",
        "                confidence = line.replace(\"CONFIDENCE:\", \"\").strip().lower()\n",
        "            elif line.startswith(\"REASON:\"):\n",
        "                reason = line.replace(\"REASON:\", \"\").strip()\n",
        "        \n",
        "        result = {\n",
        "            \"route\": route,\n",
        "            \"confidence\": confidence,\n",
        "            \"reason\": reason,\n",
        "            \"tokens_used\": tokens_used,\n",
        "            \"cost\": f\"${cost:.4f}\" if cost else \"$0.0000\"\n",
        "        }\n",
        "        \n",
        "        # Handle ambiguous queries if requested\n",
        "        if handle_ambiguity and confidence == \"low\":\n",
        "            clarification_chain = LLMChain(\n",
        "                llm=self.llm,\n",
        "                prompt=self.clarification_prompt\n",
        "            )\n",
        "            \n",
        "            clarification_response = clarification_chain.run(query=query)\n",
        "            \n",
        "            # Parse clarification response\n",
        "            lines = clarification_response.strip().split('\\n')\n",
        "            for line in lines:\n",
        "                if line.startswith(\"ALTERNATIVE_ROUTES:\"):\n",
        "                    alt_routes = line.replace(\"ALTERNATIVE_ROUTES:\", \"\").strip()\n",
        "                    if alt_routes != \"none\":\n",
        "                        result[\"alternative_routes\"] = [r.strip() for r in alt_routes.split(',')]\n",
        "                elif line.startswith(\"CLARIFICATION:\"):\n",
        "                    clarification = line.replace(\"CLARIFICATION:\", \"\").strip()\n",
        "                    if clarification != \"none\":\n",
        "                        result[\"clarification_suggestion\"] = clarification\n",
        "        \n",
        "        return result\n",
        "\n",
        "# Initialize and test the LLM router\n",
        "llm_router = LLMCompletionRouter()\n",
        "\n",
        "test_queries = [\n",
        "    \"I'm getting errors when trying to connect\",  # Ambiguous - could be technical or product\n",
        "    \"Tell me about your REST API authentication\",  # Clearly technical\n",
        "    \"Do you offer educational discounts?\",        # Clearly product\n",
        "    \"I need help with something\",                 # Very ambiguous\n",
        "]\n",
        "\n",
        "print(\"ðŸ§ª Testing LLM Completion Router\\n\" + \"=\"*50)\n",
        "for query in test_queries:\n",
        "    print(f\"Query: {query}\")\n",
        "    \n",
        "    # First try normal routing\n",
        "    result = llm_router.route(query)\n",
        "    print(f\"â†’ Route: {result['route']} (confidence: {result['confidence']})\")\n",
        "    print(f\"  Reason: {result['reason']}\")\n",
        "    print(f\"  Cost: {result['cost']}, Tokens: {result['tokens_used']}\")\n",
        "    \n",
        "    # If low confidence, try with ambiguity handling\n",
        "    if result['confidence'] == \"low\":\n",
        "        result_with_ambiguity = llm_router.route(query, handle_ambiguity=True)\n",
        "        if 'alternative_routes' in result_with_ambiguity:\n",
        "            print(f\"  Alternative routes: {result_with_ambiguity['alternative_routes']}\")\n",
        "        if 'clarification_suggestion' in result_with_ambiguity:\n",
        "            print(f\"  Suggested clarification: {result_with_ambiguity['clarification_suggestion']}\")\n",
        "    \n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4: LLM Function Calling Router\n",
        "\n",
        "OpenAI's function calling feature gives us a more structured way to get routing decisions. Instead of parsing text responses, we define routing as a function that the model can call with specific parameters. This approach is more reliable and can include additional metadata like confidence scores and multi-route suggestions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import Dict, Any, cast\n",
        "from openai import OpenAI, APIError\n",
        "\n",
        "class LLMFunctionRouter:\n",
        "    \"\"\"\n",
        "    Uses OpenAI's function calling for structured routing decisions.\n",
        "    Updated to use OpenAI Python SDK 1.x client interface with tools.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model: str = \"gpt-3.5-turbo\"):\n",
        "        self.model = model\n",
        "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "        \n",
        "        # Updated to use the new tools format\n",
        "        self.routing_tool = {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"route_query\",\n",
        "                \"description\": \"Route a user query to the appropriate knowledge base\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"primary_route\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"technical\", \"product\", \"policy\"],\n",
        "                            \"description\": \"The best knowledge base for this query\"\n",
        "                        },\n",
        "                        \"confidence_score\": {\n",
        "                            \"type\": \"number\",\n",
        "                            \"minimum\": 0,\n",
        "                            \"maximum\": 1,\n",
        "                            \"description\": \"Confidence in the routing decision (0-1)\"\n",
        "                        },\n",
        "                        \"alternative_routes\": {\n",
        "                            \"type\": \"array\",\n",
        "                            \"items\": {\n",
        "                                \"type\": \"string\",\n",
        "                                \"enum\": [\"technical\", \"product\", \"policy\"]\n",
        "                            },\n",
        "                            \"description\": \"Other knowledge bases that might be relevant\"\n",
        "                        },\n",
        "                        \"reasoning\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"Brief explanation of the routing decision\"\n",
        "                        },\n",
        "                        \"query_intent\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\n",
        "                                \"troubleshooting\",\n",
        "                                \"information_seeking\",\n",
        "                                \"purchase_decision\",\n",
        "                                \"policy_clarification\",\n",
        "                                \"how_to_guide\",\n",
        "                                \"complaint\",\n",
        "                                \"other\"\n",
        "                            ],\n",
        "                            \"description\": \"The user's intent behind the query\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"primary_route\", \"confidence_score\", \"reasoning\", \"query_intent\"]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        self.system_message = (\n",
        "            \"You are an intelligent query router for a company knowledge base. Analyze each query and \"\n",
        "            \"determine the most appropriate knowledge base:\\n\\n\"\n",
        "            \"- technical: API docs, SDKs, integration guides, debugging, error codes\\n\"\n",
        "            \"- product: Pricing, features, trials, requirements, billing\\n\"\n",
        "            \"- policy: HR, vacation, remote work, expenses, employee benefits\\n\\n\"\n",
        "            \"Consider the query's intent and provide alternative routes if the query is ambiguous.\"\n",
        "        )\n",
        "    \n",
        "    def route(self, query: str) -> Dict[str, Any]:\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": self.system_message},\n",
        "                    {\"role\": \"user\", \"content\": f\"Route this query: {query}\"}\n",
        "                ],\n",
        "                tools=cast(Any, [self.routing_tool]),\n",
        "                tool_choice=cast(Any, {\"type\": \"function\", \"function\": {\"name\": \"route_query\"}}),\n",
        "                temperature=0\n",
        "            )\n",
        "            \n",
        "            # Updated response handling for tools\n",
        "            tool_call = response.choices[0].message.tool_calls[0] if response.choices[0].message.tool_calls else None\n",
        "            \n",
        "            if not tool_call:\n",
        "                # Fallback if no tool call was made\n",
        "                return {\n",
        "                    \"route\": \"product\",\n",
        "                    \"confidence\": \"low\",\n",
        "                    \"confidence_score\": 0.3,\n",
        "                    \"reasoning\": \"No function call detected, defaulting to product\",\n",
        "                    \"error\": \"No tool call in response\"\n",
        "                }\n",
        "            \n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            confidence_score = function_args.get(\"confidence_score\", 0.5)\n",
        "            \n",
        "            if confidence_score >= 0.8:\n",
        "                confidence_level = \"high\"\n",
        "            elif confidence_score >= 0.6:\n",
        "                confidence_level = \"medium\"\n",
        "            else:\n",
        "                confidence_level = \"low\"\n",
        "            \n",
        "            # Safe access to usage with fallback\n",
        "            tokens_used = response.usage.total_tokens if response.usage else 0\n",
        "            cost_per_token = 0.000002 if \"gpt-3.5\" in self.model else 0.00003\n",
        "            cost = tokens_used * cost_per_token\n",
        "            \n",
        "            return {\n",
        "                \"route\": function_args.get(\"primary_route\"),\n",
        "                \"confidence\": confidence_level,\n",
        "                \"confidence_score\": confidence_score,\n",
        "                \"alternative_routes\": function_args.get(\"alternative_routes\", []),\n",
        "                \"reasoning\": function_args.get(\"reasoning\"),\n",
        "                \"query_intent\": function_args.get(\"query_intent\"),\n",
        "                \"tokens_used\": tokens_used,\n",
        "                \"cost\": f\"${cost:.4f}\"\n",
        "            }\n",
        "        except APIError as e:\n",
        "            return {\n",
        "                \"route\": \"product\",\n",
        "                \"confidence\": \"low\",\n",
        "                \"confidence_score\": 0.3,\n",
        "                \"reasoning\": \"Error in routing, defaulting to product\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"route\": \"product\",\n",
        "                \"confidence\": \"low\",\n",
        "                \"confidence_score\": 0.3,\n",
        "                \"reasoning\": \"Unexpected error in routing, defaulting to product\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "# Usage example\n",
        "function_router = LLMFunctionRouter()\n",
        "test_queries = [\n",
        "    \"My API calls are returning 429 errors\",\n",
        "    \"What's the difference between your plans?\",\n",
        "    \"Can I expense my home internet?\",\n",
        "    \"The dashboard is loading very slowly\",\n",
        "    \"I want to build an integration\",\n",
        "]\n",
        "\n",
        "print(\"ðŸ§ª Testing LLM Function Calling Router\\n\" + \"=\"*50)\n",
        "for query in test_queries:\n",
        "    result = function_router.route(query)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"â†’ Route: {result['route']} (confidence: {result['confidence']} - {result['confidence_score']:.2f})\")\n",
        "    print(f\"  Intent: {result.get('query_intent', 'unknown')}\")\n",
        "    print(f\"  Reason: {result['reasoning']}\")\n",
        "    if result.get(\"alternative_routes\"):\n",
        "        print(f\"  Alternatives: {result['alternative_routes']}\")\n",
        "    print(f\"  Cost: {result.get('cost', 'N/A')}\")\n",
        "    if result.get(\"error\"):\n",
        "        print(f\"  Error: {result['error']}\")\n",
        "    print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5: Zero-Shot Classification Router\n",
        "\n",
        "Zero-shot classification is fascinating because it can categorize queries without any training examples. We just describe what each category means, and the model figures out where queries belong based on its understanding of language. This is incredibly useful when you need to add new routes quickly or when you don't have many example queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ZeroShotRouter:\n",
        "    \"\"\"\n",
        "    Routes queries using zero-shot classification - no training examples needed!\n",
        "    The model understands categories from descriptions alone.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model: str = \"gpt-3.5-turbo\"):\n",
        "        self.llm = ChatOpenAI(model=model, temperature=0)\n",
        "        \n",
        "        # Define categories with natural language descriptions\n",
        "        # The model will understand these without any examples\n",
        "        self.category_descriptions = {\n",
        "            \"technical\": \"Technical documentation, APIs, programming, integrations, debugging, errors, code\",\n",
        "            \"product\": \"Product features, pricing, plans, trials, billing, subscriptions, capabilities\",\n",
        "            \"policy\": \"Company policies, HR matters, employee benefits, vacation, expenses, workplace rules\"\n",
        "        }\n",
        "        \n",
        "        # Create a zero-shot classification prompt\n",
        "        self.zero_shot_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Classify the following query into one of these categories based ONLY on their descriptions:\n",
        "\n",
        "{categories}\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Think step by step:\n",
        "1. What is the main topic of this query?\n",
        "2. Which category description best matches this topic?\n",
        "3. What is your confidence in this classification?\n",
        "\n",
        "Respond with:\n",
        "CATEGORY: [the matching category name]\n",
        "CONFIDENCE: [0-100]\n",
        "REASONING: [your step-by-step thinking]\n",
        "\"\"\")\n",
        "        \n",
        "        # Alternative prompt for multi-label classification\n",
        "        self.multi_label_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "This query might relate to multiple categories. Identify ALL relevant categories:\n",
        "\n",
        "{categories}\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "For each relevant category, provide a relevance score (0-100).\n",
        "Respond in this format:\n",
        "CATEGORIES: category1:score1, category2:score2, ...\n",
        "PRIMARY: [most relevant category]\n",
        "EXPLANATION: [why these categories are relevant]\n",
        "\"\"\")\n",
        "    \n",
        "    def format_categories(self) -> str:\n",
        "        \"\"\"Format category descriptions for the prompt\"\"\"\n",
        "        return \"\\n\".join([\n",
        "            f\"- {name}: {description}\"\n",
        "            for name, description in self.category_descriptions.items()\n",
        "        ])\n",
        "    \n",
        "    def route(self, query: str, multi_label: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Route using zero-shot classification.\n",
        "        \n",
        "        Args:\n",
        "            query: The query to classify\n",
        "            multi_label: If True, allow multiple relevant categories\n",
        "        \"\"\"\n",
        "        categories_str = self.format_categories()\n",
        "        \n",
        "        if not multi_label:\n",
        "            # Single-label classification\n",
        "            chain = LLMChain(\n",
        "                llm=self.llm,\n",
        "                prompt=self.zero_shot_prompt\n",
        "            )\n",
        "            \n",
        "            response = chain.run(categories=categories_str, query=query)\n",
        "            \n",
        "            # Parse response\n",
        "            lines = response.strip().split('\\n')\n",
        "            category = \"product\"  # default\n",
        "            confidence = 50\n",
        "            reasoning = \"Unable to classify\"\n",
        "            \n",
        "            for line in lines:\n",
        "                if line.startswith(\"CATEGORY:\"):\n",
        "                    category = line.replace(\"CATEGORY:\", \"\").strip().lower()\n",
        "                elif line.startswith(\"CONFIDENCE:\"):\n",
        "                    try:\n",
        "                        confidence = int(line.replace(\"CONFIDENCE:\", \"\").strip())\n",
        "                    except:\n",
        "                        confidence = 50\n",
        "                elif line.startswith(\"REASONING:\"):\n",
        "                    reasoning = line.replace(\"REASONING:\", \"\").strip()\n",
        "            \n",
        "            # Convert confidence to level\n",
        "            if confidence >= 80:\n",
        "                confidence_level = \"high\"\n",
        "            elif confidence >= 60:\n",
        "                confidence_level = \"medium\"\n",
        "            else:\n",
        "                confidence_level = \"low\"\n",
        "            \n",
        "            return {\n",
        "                \"route\": category,\n",
        "                \"confidence\": confidence_level,\n",
        "                \"confidence_score\": confidence,\n",
        "                \"reasoning\": reasoning,\n",
        "                \"method\": \"zero-shot\"\n",
        "            }\n",
        "        \n",
        "        else:\n",
        "            # Multi-label classification\n",
        "            chain = LLMChain(\n",
        "                llm=self.llm,\n",
        "                prompt=self.multi_label_prompt\n",
        "            )\n",
        "            \n",
        "            response = chain.run(categories=categories_str, query=query)\n",
        "            \n",
        "            # Parse multi-label response\n",
        "            lines = response.strip().split('\\n')\n",
        "            categories_scores = {}\n",
        "            primary = \"product\"\n",
        "            explanation = \"\"\n",
        "            \n",
        "            for line in lines:\n",
        "                if line.startswith(\"CATEGORIES:\"):\n",
        "                    cats_str = line.replace(\"CATEGORIES:\", \"\").strip()\n",
        "                    for cat_score in cats_str.split(','):\n",
        "                        if ':' in cat_score:\n",
        "                            cat, score = cat_score.strip().split(':')\n",
        "                            try:\n",
        "                                categories_scores[cat] = int(score)\n",
        "                            except:\n",
        "                                pass\n",
        "                elif line.startswith(\"PRIMARY:\"):\n",
        "                    primary = line.replace(\"PRIMARY:\", \"\").strip().lower()\n",
        "                elif line.startswith(\"EXPLANATION:\"):\n",
        "                    explanation = line.replace(\"EXPLANATION:\", \"\").strip()\n",
        "            \n",
        "            return {\n",
        "                \"route\": primary,\n",
        "                \"all_categories\": categories_scores,\n",
        "                \"explanation\": explanation,\n",
        "                \"method\": \"zero-shot-multi-label\"\n",
        "            }\n",
        "\n",
        "# Test zero-shot routing\n",
        "zero_shot_router = ZeroShotRouter()\n",
        "\n",
        "# Test with queries that don't explicitly mention category keywords\n",
        "test_queries = [\n",
        "    \"Something is broken and I need help\",      # Vague technical issue\n",
        "    \"How do I get started with your service?\",  # Could be product or technical\n",
        "    \"I'm going on vacation next week\",          # Clearly policy\n",
        "    \"Is there a way to reduce my monthly bill?\", # Product/billing\n",
        "]\n",
        "\n",
        "print(\"ðŸ§ª Testing Zero-Shot Router\\n\" + \"=\"*50)\n",
        "print(\"\\nSingle-label classification:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "for query in test_queries:\n",
        "    result = zero_shot_router.route(query)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"â†’ Route: {result['route']} (confidence: {result['confidence_score']}%)\")\n",
        "    print(f\"  Reasoning: {result['reasoning']}\")\n",
        "    print(\"-\"*30)\n",
        "\n",
        "print(\"\\nMulti-label classification:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "# Test multi-label on ambiguous queries\n",
        "ambiguous_queries = [\n",
        "    \"I want to integrate your API but need to know the cost first\",\n",
        "    \"Can employees use the premium features from home?\",\n",
        "]\n",
        "\n",
        "for query in ambiguous_queries:\n",
        "    result = zero_shot_router.route(query, multi_label=True)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"â†’ Primary: {result['route']}\")\n",
        "    print(f\"  All categories: {result.get('all_categories', {})}\")\n",
        "    print(f\"  Explanation: {result.get('explanation', '')}\")\n",
        "    print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 6: Language Classification Router\n",
        "\n",
        "Before routing by content, you often need to route by language. This is essential for global applications. Language detection happens quickly and accurately, allowing you to direct queries to language-specific knowledge bases or support teams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict, Any\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "class LanguageRouter:\n",
        "    \"\"\"\n",
        "    Routes queries based on detected language.\n",
        "    This typically happens before content-based routing.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "        \n",
        "        # Map languages to their knowledge bases\n",
        "        self.language_routes = {\n",
        "            \"english\": \"support_en\",\n",
        "            \"spanish\": \"support_es\",\n",
        "            \"french\": \"support_fr\",\n",
        "            \"german\": \"support_de\",\n",
        "            \"chinese\": \"support_zh\",\n",
        "            \"japanese\": \"support_ja\"\n",
        "        }\n",
        "        \n",
        "        # Simple language detection prompt\n",
        "        self.language_prompt = \"\"\"\n",
        "Detect the language of this text. Respond with ONLY the language name in English (lowercase).\n",
        "\n",
        "Text: {query}\n",
        "\n",
        "Language:\n",
        "\"\"\"\n",
        "        \n",
        "        # More detailed analysis prompt\n",
        "        self.detailed_prompt = \"\"\"\n",
        "Analyze this text and provide:\n",
        "1. Primary language\n",
        "2. Confidence level (0-100)\n",
        "3. Any mixed languages detected\n",
        "4. Script/writing system used\n",
        "\n",
        "Text: {query}\n",
        "\n",
        "Respond in this format:\n",
        "LANGUAGE: [primary language]\n",
        "CONFIDENCE: [0-100]\n",
        "MIXED_LANGUAGES: [list any other languages detected, or \"none\"]\n",
        "SCRIPT: [latin, cyrillic, chinese, arabic, etc.]\n",
        "\"\"\"\n",
        "    \n",
        "    def detect_language(self, query: str, detailed: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Detect the language of a query.\n",
        "        \n",
        "        Args:\n",
        "            query: The text to analyze\n",
        "            detailed: If True, provide detailed language analysis\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not detailed:\n",
        "                # Simple language detection\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": self.language_prompt.format(query=query)}\n",
        "                    ],\n",
        "                    temperature=0\n",
        "                )\n",
        "                \n",
        "                language = response.choices[0].message.content.strip().lower()\n",
        "                \n",
        "                # Get the appropriate route\n",
        "                route = self.language_routes.get(language, \"support_en\")  # Default to English\n",
        "                \n",
        "                return {\n",
        "                    \"language\": language,\n",
        "                    \"route\": route,\n",
        "                    \"method\": \"simple_detection\"\n",
        "                }\n",
        "            \n",
        "            else:\n",
        "                # Detailed language analysis\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": self.detailed_prompt.format(query=query)}\n",
        "                    ],\n",
        "                    temperature=0\n",
        "                )\n",
        "                \n",
        "                response_text = response.choices[0].message.content\n",
        "                \n",
        "                # Parse detailed response\n",
        "                lines = response_text.strip().split('\\n')\n",
        "                language = \"english\"\n",
        "                confidence = 50\n",
        "                mixed_languages = []\n",
        "                script = \"latin\"\n",
        "                \n",
        "                for line in lines:\n",
        "                    if line.startswith(\"LANGUAGE:\"):\n",
        "                        language = line.replace(\"LANGUAGE:\", \"\").strip().lower()\n",
        "                    elif line.startswith(\"CONFIDENCE:\"):\n",
        "                        try:\n",
        "                            confidence = int(line.replace(\"CONFIDENCE:\", \"\").strip())\n",
        "                        except:\n",
        "                            confidence = 50\n",
        "                    elif line.startswith(\"MIXED_LANGUAGES:\"):\n",
        "                        mixed = line.replace(\"MIXED_LANGUAGES:\", \"\").strip()\n",
        "                        if mixed != \"none\":\n",
        "                            mixed_languages = [lang.strip() for lang in mixed.split(',')]\n",
        "                    elif line.startswith(\"SCRIPT:\"):\n",
        "                        script = line.replace(\"SCRIPT:\", \"\").strip().lower()\n",
        "                \n",
        "                # Get route\n",
        "                route = self.language_routes.get(language, \"support_en\")\n",
        "                \n",
        "                return {\n",
        "                    \"language\": language,\n",
        "                    \"route\": route,\n",
        "                    \"confidence\": confidence,\n",
        "                    \"mixed_languages\": mixed_languages,\n",
        "                    \"script\": script,\n",
        "                    \"method\": \"detailed_detection\"\n",
        "                }\n",
        "        \n",
        "        except Exception as e:\n",
        "            # Fallback in case of API errors\n",
        "            return {\n",
        "                \"language\": \"english\",\n",
        "                \"route\": \"support_en\",\n",
        "                \"confidence\": 0,\n",
        "                \"method\": \"error_fallback\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "    \n",
        "    def route_with_content(self, query: str, content_router) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        First detect language, then route by content within that language.\n",
        "        This is how production systems typically work.\n",
        "        \"\"\"\n",
        "        # Step 1: Detect language\n",
        "        lang_result = self.detect_language(query, detailed=True)\n",
        "        \n",
        "        # Step 2: Route by content if confidence is high\n",
        "        if lang_result.get('confidence', 0) > 70:\n",
        "            content_result = content_router.route(query)\n",
        "            \n",
        "            return {\n",
        "                \"language\": lang_result['language'],\n",
        "                \"language_confidence\": lang_result['confidence'],\n",
        "                \"content_route\": content_result['route'],\n",
        "                \"content_confidence\": content_result.get('confidence', 'unknown'),\n",
        "                \"final_route\": f\"{lang_result['route']}_{content_result['route']}\",\n",
        "                \"route\": f\"{lang_result['route']}_{content_result['route']}\",  # Fix: Add this key\n",
        "                \"method\": \"language_then_content\"\n",
        "            }\n",
        "        else:\n",
        "            # Low confidence in language detection\n",
        "            return {\n",
        "                \"language\": \"uncertain\",\n",
        "                \"route\": \"support_en\",  # Default to English\n",
        "                \"confidence\": lang_result.get('confidence', 0),\n",
        "                \"suggestion\": \"Please specify your preferred language\",\n",
        "                \"method\": \"language_uncertain\"\n",
        "            }\n",
        "\n",
        "# Test language routing\n",
        "language_router = LanguageRouter()\n",
        "\n",
        "# Test queries in different languages\n",
        "multilingual_queries = [\n",
        "    \"How do I reset my password?\",                    # English\n",
        "    \"Â¿CÃ³mo restablezco mi contraseÃ±a?\",              # Spanish\n",
        "    \"Comment rÃ©initialiser mon mot de passe?\",       # French\n",
        "    \"Wie kann ich mein Passwort zurÃ¼cksetzen?\",      # German\n",
        "    \"æˆ‘å¦‚ä½•é‡ç½®å¯†ç ï¼Ÿ\",                                # Chinese\n",
        "    \"Can you help me with the API? Gracias!\",        # Mixed English/Spanish\n",
        "]\n",
        "\n",
        "print(\"ðŸ§ª Testing Language Router\\n\" + \"=\"*50)\n",
        "print(\"\\nSimple language detection:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "for query in multilingual_queries[:4]:\n",
        "    result = language_router.detect_language(query)\n",
        "    print(f\"Query: {query[:50]}...\" if len(query) > 50 else f\"Query: {query}\")\n",
        "    print(f\"â†’ Language: {result['language']}\")\n",
        "    print(f\"  Route: {result['route']}\")\n",
        "    print(\"-\"*30)\n",
        "\n",
        "print(\"\\nDetailed language analysis:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "for query in multilingual_queries[4:]:\n",
        "    result = language_router.detect_language(query, detailed=True)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"â†’ Language: {result['language']} (confidence: {result['confidence']}%)\")\n",
        "    print(f\"  Script: {result['script']}\")\n",
        "    if result['mixed_languages']:\n",
        "        print(f\"  Mixed languages: {result['mixed_languages']}\")\n",
        "    print(f\"  Route: {result['route']}\")\n",
        "    print(\"-\"*30)\n",
        "\n",
        "# Test combined language + content routing\n",
        "print(\"\\nCombined language + content routing:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "combined_test = [\n",
        "    \"What are the API rate limits?\",\n",
        "    \"Â¿CuÃ¡nto cuesta el plan profesional?\",\n",
        "]\n",
        "\n",
        "# Note: You'll need to have rule_router defined for this to work\n",
        "# rule_router = RuleBasedRouter()  # Uncomment this line if not already defined\n",
        "\n",
        "for query in combined_test:\n",
        "    try:\n",
        "        # Using a mock router if rule_router is not available\n",
        "        class MockRouter:\n",
        "            def route(self, query):\n",
        "                return {\"route\": \"technical\", \"confidence\": \"medium\"}\n",
        "        \n",
        "        mock_router = MockRouter()\n",
        "        result = language_router.route_with_content(query, mock_router)\n",
        "        \n",
        "        print(f\"Query: {query}\")\n",
        "        print(f\"â†’ Language: {result['language']} ({result.get('language_confidence', 'N/A')}%)\")\n",
        "        print(f\"  Content route: {result.get('content_route', 'N/A')}\")\n",
        "        print(f\"  Final route: {result.get('final_route', result.get('route', 'N/A'))}\")\n",
        "        print(\"-\"*30)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing query '{query}': {e}\")\n",
        "        print(\"-\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 7: Hybrid Router - Combining All Strategies\n",
        "\n",
        "In production, the best approach often combines multiple routing strategies. This gives you speed when possible, accuracy when needed, and the ability to handle edge cases gracefully. Let's build a sophisticated hybrid router that uses all the techniques we've learned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HybridRouter:\n",
        "    \"\"\"\n",
        "    A production-ready router that combines multiple strategies intelligently.\n",
        "    This is what you'd actually use in a real application.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 use_rule_based: bool = True,\n",
        "                 use_semantic: bool = True,\n",
        "                 use_llm: bool = True,\n",
        "                 use_language: bool = True):\n",
        "        \n",
        "        # Initialize all routers based on configuration\n",
        "        self.use_rule_based = use_rule_based\n",
        "        self.use_semantic = use_semantic\n",
        "        self.use_llm = use_llm\n",
        "        self.use_language = use_language\n",
        "        \n",
        "        if use_rule_based:\n",
        "            self.rule_router = RuleBasedRouter()\n",
        "        if use_semantic:\n",
        "            self.semantic_router = SemanticRouter()\n",
        "        if use_llm:\n",
        "            self.llm_router = LLMCompletionRouter()\n",
        "        if use_language:\n",
        "            self.language_router = LanguageRouter()\n",
        "        \n",
        "        # Configuration for routing strategy\n",
        "        self.confidence_thresholds = {\n",
        "            \"high\": 0.8,\n",
        "            \"medium\": 0.6,\n",
        "            \"low\": 0.4\n",
        "        }\n",
        "        \n",
        "        # Weights for combining different router scores\n",
        "        self.router_weights = {\n",
        "            \"rule\": 0.25,\n",
        "            \"semantic\": 0.35,\n",
        "            \"llm\": 0.40\n",
        "        }\n",
        "    \n",
        "    def route(self, query: str, strategy: str = \"cascade\") -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Route using specified strategy.\n",
        "        \n",
        "        Strategies:\n",
        "        - cascade: Try fast methods first, escalate if low confidence\n",
        "        - ensemble: Combine all methods and vote\n",
        "        - adaptive: Choose strategy based on query characteristics\n",
        "        \"\"\"\n",
        "        \n",
        "        # First, detect language if enabled\n",
        "        language_info = None\n",
        "        if self.use_language:\n",
        "            language_info = self.language_router.detect_language(query)\n",
        "            if language_info['language'] != 'english':\n",
        "                # For non-English, return language-specific route\n",
        "                return {\n",
        "                    \"route\": language_info['route'],\n",
        "                    \"strategy\": \"language_routing\",\n",
        "                    \"language\": language_info['language'],\n",
        "                    \"details\": language_info\n",
        "                }\n",
        "        \n",
        "        if strategy == \"cascade\":\n",
        "            return self._cascade_routing(query)\n",
        "        elif strategy == \"ensemble\":\n",
        "            return self._ensemble_routing(query)\n",
        "        elif strategy == \"adaptive\":\n",
        "            return self._adaptive_routing(query)\n",
        "        else:\n",
        "            return self._cascade_routing(query)  # Default\n",
        "    \n",
        "    def _cascade_routing(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Try routers in order of speed/cost, escalating only if needed.\n",
        "        This is the most efficient strategy for production.\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # Step 1: Try rule-based (fastest)\n",
        "        if self.use_rule_based:\n",
        "            rule_result = self.rule_router.route(query)\n",
        "            results['rule'] = rule_result\n",
        "            \n",
        "            if rule_result['confidence'] == 'high':\n",
        "                return {\n",
        "                    \"route\": rule_result['route'],\n",
        "                    \"confidence\": \"high\",\n",
        "                    \"strategy\": \"cascade_rule\",\n",
        "                    \"details\": results\n",
        "                }\n",
        "        \n",
        "        # Step 2: Try semantic (medium speed)\n",
        "        if self.use_semantic:\n",
        "            semantic_result = self.semantic_router.route(query)\n",
        "            results['semantic'] = semantic_result\n",
        "            \n",
        "            if semantic_result['confidence'] == 'high':\n",
        "                return {\n",
        "                    \"route\": semantic_result['route'],\n",
        "                    \"confidence\": \"high\",\n",
        "                    \"strategy\": \"cascade_semantic\",\n",
        "                    \"details\": results\n",
        "                }\n",
        "        \n",
        "        # Step 3: Use LLM (slowest but most accurate)\n",
        "        if self.use_llm:\n",
        "            llm_result = self.llm_router.route(query)\n",
        "            results['llm'] = llm_result\n",
        "            \n",
        "            return {\n",
        "                \"route\": llm_result['route'],\n",
        "                \"confidence\": llm_result['confidence'],\n",
        "                \"strategy\": \"cascade_llm\",\n",
        "                \"details\": results\n",
        "            }\n",
        "        \n",
        "        # Fallback if no routers are enabled\n",
        "        return {\n",
        "            \"route\": \"product\",\n",
        "            \"confidence\": \"low\",\n",
        "            \"strategy\": \"cascade_default\",\n",
        "            \"details\": results\n",
        "        }\n",
        "    \n",
        "    def _ensemble_routing(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Run all routers and combine their results.\n",
        "        More accurate but slower and more expensive.\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        weighted_scores = {\"technical\": 0.0, \"product\": 0.0, \"policy\": 0.0}\n",
        "        \n",
        "        # Collect votes from all routers\n",
        "        if self.use_rule_based:\n",
        "            rule_result = self.rule_router.route(query)\n",
        "            results['rule'] = rule_result\n",
        "            route = rule_result['route']\n",
        "            \n",
        "            # Add weighted vote\n",
        "            confidence_multiplier = {\"high\": 1.0, \"medium\": 0.7, \"low\": 0.4}.get(\n",
        "                rule_result['confidence'], 0.4\n",
        "            )\n",
        "            weighted_scores[route] += self.router_weights['rule'] * confidence_multiplier\n",
        "        \n",
        "        if self.use_semantic:\n",
        "            semantic_result = self.semantic_router.route(query)\n",
        "            results['semantic'] = semantic_result\n",
        "            route = semantic_result['route']\n",
        "            \n",
        "            # Add weighted vote based on similarity score\n",
        "            weighted_scores[route] += self.router_weights['semantic'] * semantic_result['similarity']\n",
        "        \n",
        "        if self.use_llm:\n",
        "            llm_result = self.llm_router.route(query)\n",
        "            results['llm'] = llm_result\n",
        "            route = llm_result['route']\n",
        "            \n",
        "            confidence_multiplier = {\"high\": 1.0, \"medium\": 0.7, \"low\": 0.4}.get(\n",
        "                llm_result['confidence'], 0.4\n",
        "            )\n",
        "            weighted_scores[route] += self.router_weights['llm'] * confidence_multiplier\n",
        "        \n",
        "        # Determine winner\n",
        "        best_route = max(weighted_scores.keys(), key=lambda k: weighted_scores[k])\n",
        "        best_score = weighted_scores[best_route]\n",
        "        \n",
        "        # Calculate confidence based on agreement\n",
        "        if best_score > 0.7:\n",
        "            confidence = \"high\"\n",
        "        elif best_score > 0.5:\n",
        "            confidence = \"medium\"\n",
        "        else:\n",
        "            confidence = \"low\"\n",
        "        \n",
        "        return {\n",
        "            \"route\": best_route,\n",
        "            \"confidence\": confidence,\n",
        "            \"weighted_scores\": weighted_scores,\n",
        "            \"strategy\": \"ensemble\",\n",
        "            \"details\": results\n",
        "        }\n",
        "    \n",
        "    def _adaptive_routing(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Choose routing strategy based on query characteristics.\n",
        "        This is the smartest but most complex approach.\n",
        "        \"\"\"\n",
        "        query_length = len(query.split())\n",
        "        has_technical_indicators = any(word in query.lower() for word in \n",
        "                                      ['api', 'error', 'code', 'integration', 'webhook'])\n",
        "        has_product_indicators = any(word in query.lower() for word in \n",
        "                                    ['price', 'plan', 'trial', 'feature', 'cost'])\n",
        "        has_policy_indicators = any(word in query.lower() for word in \n",
        "                                   ['vacation', 'policy', 'expense', 'remote', 'pto'])\n",
        "        \n",
        "        # Count indicators\n",
        "        indicator_count = sum([has_technical_indicators, has_product_indicators, has_policy_indicators])\n",
        "        \n",
        "        # Choose strategy based on query characteristics\n",
        "        if indicator_count == 1 and query_length < 10:\n",
        "            # Clear, simple query - use cascade for speed\n",
        "            return self._cascade_routing(query)\n",
        "        elif indicator_count > 1 or query_length > 20:\n",
        "            # Complex or ambiguous query - use ensemble for accuracy\n",
        "            return self._ensemble_routing(query)\n",
        "        else:\n",
        "            # Medium complexity - use cascade but note it might need ensemble\n",
        "            result = self._cascade_routing(query)\n",
        "            if result['confidence'] == 'low':\n",
        "                # Low confidence, try ensemble\n",
        "                result = self._ensemble_routing(query)\n",
        "                result['strategy'] = 'adaptive_escalated'\n",
        "            else:\n",
        "                result['strategy'] = 'adaptive_cascade'\n",
        "            return result\n",
        "\n",
        "# Initialize the hybrid router with all strategies\n",
        "hybrid_router = HybridRouter(\n",
        "    use_rule_based=True,\n",
        "    use_semantic=True,\n",
        "    use_llm=True,\n",
        "    use_language=False  # Disable for these English-only tests\n",
        ")\n",
        "\n",
        "# Test different routing strategies\n",
        "test_queries = [\n",
        "    \"API authentication\",                              # Simple, clear\n",
        "    \"How much does the professional plan cost?\",      # Clear question\n",
        "    \"I'm having issues connecting to your service\",    # Ambiguous\n",
        "    \"I want to integrate your API into my app but I need to know the pricing first and whether you offer educational discounts\",  # Complex\n",
        "]\n",
        "\n",
        "strategies = [\"cascade\", \"ensemble\", \"adaptive\"]\n",
        "\n",
        "print(\"ðŸ§ª Testing Hybrid Router with Different Strategies\\n\" + \"=\"*50)\n",
        "\n",
        "for strategy in strategies:\n",
        "    print(f\"\\nðŸ“Š Strategy: {strategy.upper()}\")\n",
        "    print(\"-\"*40)\n",
        "    \n",
        "    for query in test_queries:\n",
        "        start_time = time.time()\n",
        "        result = hybrid_router.route(query, strategy=strategy)\n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        print(f\"Query: {query[:50]}...\" if len(query) > 50 else f\"Query: {query}\")\n",
        "        print(f\"â†’ Route: {result['route']} (confidence: {result['confidence']})\")\n",
        "        print(f\"  Strategy used: {result['strategy']}\")\n",
        "        print(f\"  Time: {elapsed:.2f}s\")\n",
        "        \n",
        "        if 'weighted_scores' in result:\n",
        "            scores_str = ', '.join(f\"{k}:{v:.2f}\" for k,v in result['weighted_scores'].items())\n",
        "            print(f\"  Scores: {scores_str}\")\n",
        "        \n",
        "        print(\"-\"*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 8: Complete RAG System with Smart Routing\n",
        "\n",
        "Now let's put everything together into a production-ready RAG system that uses intelligent routing to provide accurate, fast responses. This system will route queries to the appropriate knowledge base and generate comprehensive answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmartRAGSystem:\n",
        "    \"\"\"\n",
        "    A complete RAG system with intelligent query routing.\n",
        "    This is what you'd deploy in production.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, collections: Dict[str, chromadb.Collection], \n",
        "                 router: HybridRouter):\n",
        "        self.collections = collections\n",
        "        self.router = router\n",
        "        \n",
        "        # Initialize the answer generation LLM\n",
        "        self.answer_llm = ChatOpenAI(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            temperature=0.7  # Slightly higher for more natural answers\n",
        "        )\n",
        "        \n",
        "        # Answer generation prompt\n",
        "        self.answer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a helpful assistant answering questions based on provided context.\n",
        "Use the context to provide accurate, helpful answers. If the context doesn't \n",
        "contain relevant information, say so honestly.\n",
        "\n",
        "Context from {source} knowledge base:\n",
        "{context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Please provide a clear, concise answer:\n",
        "\"\"\")\n",
        "    \n",
        "    def search_collection(self, collection_name: str, query: str, \n",
        "                         k: int = 3) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Search a specific collection for relevant documents.\n",
        "        \"\"\"\n",
        "        if collection_name not in self.collections:\n",
        "            return []\n",
        "        \n",
        "        collection = self.collections[collection_name]\n",
        "        \n",
        "        # Search the collection\n",
        "        results = collection.query(\n",
        "            query_texts=[query],\n",
        "            n_results=k\n",
        "        )\n",
        "        \n",
        "        # Format results\n",
        "        formatted_results = []\n",
        "        if results['documents'] and len(results['documents'][0]) > 0:\n",
        "            for i, doc in enumerate(results['documents'][0]):\n",
        "                formatted_results.append({\n",
        "                    \"content\": doc,\n",
        "                    \"metadata\": results['metadatas'][0][i] if results['metadatas'] else {},\n",
        "                    \"distance\": results['distances'][0][i] if results['distances'] else 0\n",
        "                })\n",
        "        \n",
        "        return formatted_results\n",
        "    \n",
        "    def generate_answer(self, query: str, context: str, source: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate an answer based on retrieved context.\n",
        "        \"\"\"\n",
        "        chain = LLMChain(llm=self.answer_llm, prompt=self.answer_prompt)\n",
        "        \n",
        "        with get_openai_callback() as cb:\n",
        "            answer = chain.run(\n",
        "                query=query,\n",
        "                context=context,\n",
        "                source=source\n",
        "            )\n",
        "            \n",
        "            # Store cost info for monitoring\n",
        "            self.last_answer_cost = cb.total_cost\n",
        "            self.last_answer_tokens = cb.total_tokens\n",
        "        \n",
        "        return answer.strip()\n",
        "    \n",
        "    def process_query(self, query: str, routing_strategy: str = \"adaptive\",\n",
        "                     verbose: bool = True) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Complete pipeline: route, search, and answer a query.\n",
        "        \n",
        "        Args:\n",
        "            query: The user's question\n",
        "            routing_strategy: Which routing strategy to use\n",
        "            verbose: Whether to print progress information\n",
        "        \"\"\"\n",
        "        if verbose:\n",
        "            print(f\"\\nðŸ” Processing query: {query}\")\n",
        "            print(\"=\"*50)\n",
        "        \n",
        "        # Step 1: Route the query\n",
        "        start_time = time.time()\n",
        "        routing_result = self.router.route(query, strategy=routing_strategy)\n",
        "        routing_time = time.time() - start_time\n",
        "        \n",
        "        route = routing_result['route']\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"ðŸ“ Routed to: {route} knowledge base\")\n",
        "            print(f\"   Confidence: {routing_result['confidence']}\")\n",
        "            print(f\"   Strategy: {routing_result['strategy']}\")\n",
        "            print(f\"   Routing time: {routing_time:.2f}s\")\n",
        "        \n",
        "        # Step 2: Search the appropriate collection\n",
        "        start_time = time.time()\n",
        "        search_results = self.search_collection(route, query)\n",
        "        search_time = time.time() - start_time\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"\\nðŸ“š Found {len(search_results)} relevant documents\")\n",
        "            print(f\"   Search time: {search_time:.2f}s\")\n",
        "        \n",
        "        # Step 3: Generate answer\n",
        "        if search_results:\n",
        "            # Combine context from search results\n",
        "            context = \"\\n\\n\".join([doc['content'] for doc in search_results])\n",
        "            \n",
        "            start_time = time.time()\n",
        "            answer = self.generate_answer(query, context, route)\n",
        "            answer_time = time.time() - start_time\n",
        "            \n",
        "            if verbose:\n",
        "                print(f\"\\nðŸ’¡ Answer generated\")\n",
        "                print(f\"   Generation time: {answer_time:.2f}s\")\n",
        "                print(f\"   Tokens used: {self.last_answer_tokens}\")\n",
        "                print(f\"   Cost: ${self.last_answer_cost:.4f}\")\n",
        "        else:\n",
        "            answer = \"I couldn't find relevant information to answer your question. Please try rephrasing or contact support.\"\n",
        "            answer_time = 0\n",
        "        \n",
        "        total_time = routing_time + search_time + answer_time\n",
        "        \n",
        "        if verbose:\n",
        "            print(f\"\\nâ±ï¸  Total processing time: {total_time:.2f}s\")\n",
        "            print(\"=\"*50)\n",
        "        \n",
        "        return {\n",
        "            \"query\": query,\n",
        "            \"answer\": answer,\n",
        "            \"route\": route,\n",
        "            \"routing_confidence\": routing_result['confidence'],\n",
        "            \"routing_strategy\": routing_result['strategy'],\n",
        "            \"documents_found\": len(search_results),\n",
        "            \"source_documents\": search_results,\n",
        "            \"timing\": {\n",
        "                \"routing\": routing_time,\n",
        "                \"search\": search_time,\n",
        "                \"generation\": answer_time,\n",
        "                \"total\": total_time\n",
        "            },\n",
        "            \"cost\": {\n",
        "                \"tokens\": getattr(self, 'last_answer_tokens', 0),\n",
        "                \"amount\": getattr(self, 'last_answer_cost', 0)\n",
        "            }\n",
        "        }\n",
        "\n",
        "# Initialize the complete RAG system\n",
        "collections_dict = {\n",
        "    \"technical\": technical_collection,\n",
        "    \"product\": product_collection,\n",
        "    \"policy\": policy_collection,\n",
        "    \"support_en\": support_en_collection,\n",
        "    \"support_es\": support_es_collection\n",
        "}\n",
        "\n",
        "# Create a hybrid router with all capabilities\n",
        "production_router = HybridRouter(\n",
        "    use_rule_based=True,\n",
        "    use_semantic=True,\n",
        "    use_llm=True,\n",
        "    use_language=True\n",
        ")\n",
        "\n",
        "# Initialize the RAG system\n",
        "rag_system = SmartRAGSystem(\n",
        "    collections=collections_dict,\n",
        "    router=production_router\n",
        ")\n",
        "\n",
        "print(\"ðŸš€ Smart RAG System initialized and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing the Complete System\n",
        "\n",
        "Let's test our production-ready RAG system with various queries to see how intelligent routing improves both speed and accuracy. We'll compare different routing strategies to understand their trade-offs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test queries covering different scenarios\n",
        "test_scenarios = [\n",
        "    {\n",
        "        \"query\": \"How do I authenticate API requests with OAuth?\",\n",
        "        \"expected_route\": \"technical\",\n",
        "        \"description\": \"Clear technical question\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What's the price difference between Professional and Enterprise?\",\n",
        "        \"expected_route\": \"product\",\n",
        "        \"description\": \"Clear product question\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How many days off can I take for my wedding?\",\n",
        "        \"expected_route\": \"policy\",\n",
        "        \"description\": \"Clear policy question\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"The system is giving me errors\",\n",
        "        \"expected_route\": \"technical\",\n",
        "        \"description\": \"Ambiguous - could be technical or product\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Â¿CÃ³mo restablezco mi contraseÃ±a?\",\n",
        "        \"expected_route\": \"support_es\",\n",
        "        \"description\": \"Spanish language query\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"ðŸ§ª Testing Complete RAG System\\n\" + \"=\"*70)\n",
        "\n",
        "for scenario in test_scenarios[:3]:  # Test first 3 with detailed output\n",
        "    print(f\"\\nðŸ“ Test: {scenario['description']}\")\n",
        "    print(f\"Expected route: {scenario['expected_route']}\")\n",
        "    \n",
        "    result = rag_system.process_query(\n",
        "        scenario['query'],\n",
        "        routing_strategy=\"adaptive\",\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nðŸ“‹ ANSWER:\")\n",
        "    print(\"-\"*50)\n",
        "    print(result['answer'])\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    # Check if routing was correct\n",
        "    if result['route'] == scenario['expected_route']:\n",
        "        print(\"âœ… Routing correct!\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  Routed to {result['route']} instead of {scenario['expected_route']}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Comparison: Routing Strategies\n",
        "\n",
        "Let's compare the performance of different routing strategies to understand when to use each one. This will help you make informed decisions about which strategy to use in production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_routing_strategies(queries: List[str], strategies: List[str]):\n",
        "    \"\"\"\n",
        "    Compare different routing strategies on the same queries.\n",
        "    \"\"\"\n",
        "    results = {strategy: [] for strategy in strategies}\n",
        "    \n",
        "    for query in queries:\n",
        "        print(f\"\\nQuery: {query[:60]}...\" if len(query) > 60 else f\"\\nQuery: {query}\")\n",
        "        print(\"-\"*40)\n",
        "        \n",
        "        for strategy in strategies:\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # Just route, don't search or generate answers for this comparison\n",
        "            routing_result = production_router.route(query, strategy=strategy)\n",
        "            \n",
        "            elapsed = time.time() - start_time\n",
        "            \n",
        "            results[strategy].append({\n",
        "                \"query\": query,\n",
        "                \"route\": routing_result['route'],\n",
        "                \"confidence\": routing_result['confidence'],\n",
        "                \"time\": elapsed\n",
        "            })\n",
        "            \n",
        "            print(f\"{strategy:12} â†’ {routing_result['route']:10} \"\n",
        "                  f\"({routing_result['confidence']:6}) - {elapsed:.3f}s\")\n",
        "    \n",
        "    # Calculate averages\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY STATISTICS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for strategy in strategies:\n",
        "        times = [r['time'] for r in results[strategy]]\n",
        "        avg_time = sum(times) / len(times)\n",
        "        \n",
        "        # Count confidence levels\n",
        "        confidence_counts = {\"high\": 0, \"medium\": 0, \"low\": 0}\n",
        "        for r in results[strategy]:\n",
        "            confidence_counts[r['confidence']] += 1\n",
        "        \n",
        "        print(f\"\\n{strategy.upper()}:\")\n",
        "        print(f\"  Average time: {avg_time:.3f}s\")\n",
        "        print(f\"  Confidence distribution:\")\n",
        "        print(f\"    High:   {confidence_counts['high']}/{len(queries)}\")\n",
        "        print(f\"    Medium: {confidence_counts['medium']}/{len(queries)}\")\n",
        "        print(f\"    Low:    {confidence_counts['low']}/{len(queries)}\")\n",
        "\n",
        "# Run the comparison\n",
        "comparison_queries = [\n",
        "    \"API rate limits\",\n",
        "    \"How much for enterprise?\",\n",
        "    \"Vacation policy details\",\n",
        "    \"System performance issues\",\n",
        "    \"I need help integrating your API and understanding the pricing\"\n",
        "]\n",
        "\n",
        "print(\"ðŸ“Š Comparing Routing Strategies\\n\" + \"=\"*60)\n",
        "compare_routing_strategies(comparison_queries, [\"cascade\", \"ensemble\", \"adaptive\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices and Production Considerations\n",
        "\n",
        "Now that you've seen all the routing techniques in action, let's discuss how to implement them effectively in production. These guidelines come from real-world experience building RAG systems at scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProductionBestPractices:\n",
        "    \"\"\"\n",
        "    A collection of best practices for production query routing.\n",
        "    These are patterns you should follow in real applications.\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_caching():\n",
        "        \"\"\"\n",
        "        Implement caching to avoid redundant routing decisions.\n",
        "        \"\"\"\n",
        "        from functools import lru_cache\n",
        "        import hashlib\n",
        "        \n",
        "        class CachedRouter:\n",
        "            def __init__(self, base_router, cache_size: int = 1000):\n",
        "                self.base_router = base_router\n",
        "                self.cache_size = cache_size\n",
        "                self.cache = {}\n",
        "            \n",
        "            def _hash_query(self, query: str) -> str:\n",
        "                \"\"\"Create a hash of the query for caching\"\"\"\n",
        "                return hashlib.md5(query.encode()).hexdigest()\n",
        "            \n",
        "            def route(self, query: str) -> Dict[str, Any]:\n",
        "                # Check cache first\n",
        "                query_hash = self._hash_query(query)\n",
        "                \n",
        "                if query_hash in self.cache:\n",
        "                    cached_result = self.cache[query_hash].copy()\n",
        "                    cached_result['from_cache'] = True\n",
        "                    return cached_result\n",
        "                \n",
        "                # Route and cache the result\n",
        "                result = self.base_router.route(query)\n",
        "                \n",
        "                # Implement simple LRU by removing oldest if cache is full\n",
        "                if len(self.cache) >= self.cache_size:\n",
        "                    # Remove the oldest entry (first key)\n",
        "                    oldest_key = next(iter(self.cache))\n",
        "                    del self.cache[oldest_key]\n",
        "                \n",
        "                self.cache[query_hash] = result\n",
        "                result['from_cache'] = False\n",
        "                \n",
        "                return result\n",
        "        \n",
        "        return CachedRouter\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_monitoring():\n",
        "        \"\"\"\n",
        "        Add monitoring and logging for production debugging.\n",
        "        \"\"\"\n",
        "        import logging\n",
        "        from datetime import datetime\n",
        "        \n",
        "        class MonitoredRouter:\n",
        "            def __init__(self, base_router):\n",
        "                self.base_router = base_router\n",
        "                self.metrics = {\n",
        "                    \"total_queries\": 0,\n",
        "                    \"routes\": {},\n",
        "                    \"avg_confidence\": [],\n",
        "                    \"errors\": 0\n",
        "                }\n",
        "                \n",
        "                # Set up logging\n",
        "                logging.basicConfig(level=logging.INFO)\n",
        "                self.logger = logging.getLogger(__name__)\n",
        "            \n",
        "            def route(self, query: str) -> Dict[str, Any]:\n",
        "                start_time = time.time()\n",
        "                \n",
        "                try:\n",
        "                    result = self.base_router.route(query)\n",
        "                    \n",
        "                    # Update metrics\n",
        "                    self.metrics['total_queries'] += 1\n",
        "                    route = result.get('route', 'unknown')\n",
        "                    self.metrics['routes'][route] = self.metrics['routes'].get(route, 0) + 1\n",
        "                    \n",
        "                    # Log the routing decision\n",
        "                    self.logger.info(\n",
        "                        f\"Query routed | Route: {route} | \"\n",
        "                        f\"Confidence: {result.get('confidence', 'N/A')} | \"\n",
        "                        f\"Time: {time.time() - start_time:.3f}s | \"\n",
        "                        f\"Query: {query[:50]}...\"\n",
        "                    )\n",
        "                    \n",
        "                    return result\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    self.metrics['errors'] += 1\n",
        "                    self.logger.error(f\"Routing error: {e} | Query: {query}\")\n",
        "                    \n",
        "                    # Fallback routing\n",
        "                    return {\n",
        "                        \"route\": \"product\",\n",
        "                        \"confidence\": \"low\",\n",
        "                        \"error\": str(e)\n",
        "                    }\n",
        "            \n",
        "            def get_metrics(self) -> Dict[str, Any]:\n",
        "                \"\"\"Get current metrics\"\"\"\n",
        "                return self.metrics\n",
        "        \n",
        "        return MonitoredRouter\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_fallback_handling():\n",
        "        \"\"\"\n",
        "        Implement robust fallback mechanisms for production reliability.\n",
        "        \"\"\"\n",
        "        class FallbackRouter:\n",
        "            def __init__(self, primary_router, fallback_router):\n",
        "                self.primary_router = primary_router\n",
        "                self.fallback_router = fallback_router\n",
        "            \n",
        "            def route(self, query: str) -> Dict[str, Any]:\n",
        "                try:\n",
        "                    # Try primary router first\n",
        "                    result = self.primary_router.route(query)\n",
        "                    \n",
        "                    # If confidence is too low, try fallback\n",
        "                    if result.get('confidence') == 'low':\n",
        "                        fallback_result = self.fallback_router.route(query)\n",
        "                        if fallback_result.get('confidence', 'low') != 'low':\n",
        "                            fallback_result['used_fallback'] = True\n",
        "                            return fallback_result\n",
        "                    \n",
        "                    return result\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    # Primary failed, use fallback\n",
        "                    try:\n",
        "                        result = self.fallback_router.route(query)\n",
        "                        result['used_fallback'] = True\n",
        "                        result['primary_error'] = str(e)\n",
        "                        return result\n",
        "                    except:\n",
        "                        # Both failed, return safe default\n",
        "                        return {\n",
        "                            \"route\": \"product\",\n",
        "                            \"confidence\": \"low\",\n",
        "                            \"error\": \"All routers failed\"\n",
        "                        }\n",
        "        \n",
        "        return FallbackRouter\n",
        "\n",
        "# Demonstrate best practices\n",
        "print(\"ðŸ“š Production Best Practices Examples\\n\" + \"=\"*50)\n",
        "\n",
        "# Example 1: Caching\n",
        "print(\"\\n1. CACHING EXAMPLE:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "CachedRouter = ProductionBestPractices.add_caching()\n",
        "cached_router = CachedRouter(rule_router, cache_size=100)\n",
        "\n",
        "# First call - not cached\n",
        "result1 = cached_router.route(\"How do I use the API?\")\n",
        "print(f\"First call - From cache: {result1.get('from_cache', False)}\")\n",
        "\n",
        "# Second call - should be cached\n",
        "result2 = cached_router.route(\"How do I use the API?\")\n",
        "print(f\"Second call - From cache: {result2.get('from_cache', False)}\")\n",
        "\n",
        "# Example 2: Monitoring\n",
        "print(\"\\n2. MONITORING EXAMPLE:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "MonitoredRouter = ProductionBestPractices.add_monitoring()\n",
        "monitored_router = MonitoredRouter(rule_router)\n",
        "\n",
        "# Route some queries\n",
        "test_queries = [\n",
        "    \"API documentation\",\n",
        "    \"Pricing information\",\n",
        "    \"Vacation policy\"\n",
        "]\n",
        "\n",
        "for q in test_queries:\n",
        "    monitored_router.route(q)\n",
        "\n",
        "# Get metrics\n",
        "metrics = monitored_router.get_metrics()\n",
        "print(f\"Total queries: {metrics['total_queries']}\")\n",
        "print(f\"Route distribution: {metrics['routes']}\")\n",
        "print(f\"Errors: {metrics['errors']}\")\n",
        "\n",
        "# Example 3: Fallback handling\n",
        "print(\"\\n3. FALLBACK EXAMPLE:\")\n",
        "print(\"-\"*30)\n",
        "\n",
        "FallbackRouter = ProductionBestPractices.add_fallback_handling()\n",
        "# Use semantic router as primary, rule-based as fallback\n",
        "robust_router = FallbackRouter(semantic_router, rule_router)\n",
        "\n",
        "result = robust_router.route(\"Something about our service\")\n",
        "print(f\"Route: {result['route']}\")\n",
        "print(f\"Used fallback: {result.get('used_fallback', False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways and Recommendations\n",
        "\n",
        "After building all these routing systems, here's what you should remember for your own implementations:\n",
        "\n",
        "### When to Use Each Router Type\n",
        "\n",
        "**Rule-Based Routing** is perfect when:\n",
        "- You have clear, domain-specific terminology\n",
        "- Speed is critical (sub-100ms responses needed)\n",
        "- You want predictable, explainable behavior\n",
        "- Budget is tight (no API costs)\n",
        "\n",
        "**Semantic Routing** shines when:\n",
        "- Queries use varied language to mean the same thing\n",
        "- You have good example queries for each category\n",
        "- You need fast responses but better accuracy than rules\n",
        "- You want to handle synonyms and related concepts\n",
        "\n",
        "**LLM-Based Routing** (Completion or Function Calling) is best when:\n",
        "- Queries are complex or ambiguous\n",
        "- You need reasoning about intent\n",
        "- Accuracy is more important than speed\n",
        "- You can afford the API costs\n",
        "\n",
        "**Zero-Shot Classification** works great when:\n",
        "- You're adding new categories frequently\n",
        "- You don't have training examples\n",
        "- Categories can be described in natural language\n",
        "- You need quick prototyping\n",
        "\n",
        "**Language Routing** is essential when:\n",
        "- You serve a global audience\n",
        "- Content exists in multiple languages\n",
        "- You need to route to regional support teams\n",
        "\n",
        "### Production Architecture Recommendations\n",
        "\n",
        "1. **Start Simple**: Begin with rule-based or semantic routing. They're fast, cheap, and often sufficient.\n",
        "\n",
        "2. **Use Cascading**: Try fast methods first, escalate to expensive ones only when needed.\n",
        "\n",
        "3. **Cache Aggressively**: Many users ask similar questions. Cache routing decisions for common queries.\n",
        "\n",
        "4. **Monitor Everything**: Track which routes are used, confidence levels, and response times.\n",
        "\n",
        "5. **Plan for Failure**: Always have fallback routes. Default to your most general knowledge base.\n",
        "\n",
        "6. **Test with Real Data**: Your users will surprise you. Collect real queries and continuously improve.\n",
        "\n",
        "### Cost Optimization Tips\n",
        "\n",
        "- Semantic routing with cached embeddings costs almost nothing per query\n",
        "- Rule-based routing is completely free after development\n",
        "- LLM routing costs $0.001-0.01 per query depending on model\n",
        "- Batch embed your example queries for semantic routing\n",
        "- Use smaller models (GPT-3.5) for routing, save GPT-4 for answer generation\n",
        "\n",
        "### Final Thoughts\n",
        "\n",
        "Query routing is what transforms a basic RAG system into a production-ready application. The right routing strategy can improve response accuracy by 40-60% while reducing costs by 30-50%. Start with the approach that matches your current needs, but build in flexibility to evolve as you learn from your users.\n",
        "\n",
        "Remember: the best router is the one that works reliably for YOUR specific use case. Test thoroughly, monitor continuously, and iterate based on real user feedback.\n",
        "\n",
        "Happy routing! ðŸš€\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
